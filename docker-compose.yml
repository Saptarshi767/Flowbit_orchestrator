version: '3.8'

services:
  langflow:
    image: langflowai/langflow:latest
    ports:
      - "7860:7860"
    environment:
      - LANGFLOW_SUPERUSER=admin
      - LANGFLOW_SUPERUSER_PASSWORD=admin
    volumes:
      - ./flows:/app/flows
    networks:
      - flowbit-network
    restart: unless-stopped

  redis:
    image: redis:latest
    ports:
      - "6379:6379"
    networks:
      - flowbit-network
    restart: unless-stopped

  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    command: serve
    networks:
      - flowbit-network
    restart: unless-stopped

  runner:
    build:
      context: .
      dockerfile: Dockerfile.runner
    volumes:
      - ./flows:/app/flows
      - ./logs:/app/logs
      - ./executions.json:/app/executions.json
    environment:
      - OLLAMA_HOST=http://ollama:11434
    depends_on:
      - ollama
    networks:
      - flowbit-network
    restart: unless-stopped

  web:
    build:
      context: .
      dockerfile: Dockerfile.nextjs
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=production
      - OLLAMA_URL=http://ollama:11434
      - LANGFLOW_URL=http://langflow:7860
    # Only mount persistent data if needed
    volumes:
      - ./public:/app/public
    depends_on:
      - runner
      - redis
      - ollama
      - langflow
    networks:
      - flowbit-network
    restart: unless-stopped

volumes:
  ollama_data:

networks:
  flowbit-network:
    driver: bridge